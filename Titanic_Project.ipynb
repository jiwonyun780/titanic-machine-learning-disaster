import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

train_data = pd.read_csv('train.csv')
test_data = pd.read_csv('test.csv')
train_data.head(), test_data.head()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder

# Preprocessing: Handle missing values and encode categorical variables
def preprocess_data(data, is_train=True):
    # Fill missing values for 'Age' with median
    imputer = SimpleImputer(strategy="median")
    data['Age'] = imputer.fit_transform(data[['Age']])

    # Fill missing values for 'Embarked' with the most frequent value (mode)
    data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)

    # Drop 'Cabin' column due to many missing values and high sparsity
    data.drop('Cabin', axis=1, inplace=True)

    # Encode categorical variables: 'Sex', 'Embarked'
    for col in ['Sex', 'Embarked']:
        le = LabelEncoder()
        data[col] = le.fit_transform(data[col])

    # Drop non-relevant columns for modeling
    data.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)

    if is_train:
        # Separate target variable
        X = data.drop('Survived', axis=1)
        y = data['Survived']
        return X, y
    else:
        return data

# Preprocess training and testing data
X, y = preprocess_data(train_data)
X_test = preprocess_data(test_data, is_train=False)

# Split the training data into training and validation subsets
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a logistic regression model
model = LogisticRegression(random_state=42, max_iter=500)
model.fit(X_train, y_train)

# Evaluate the model on validation data
y_val_pred = model.predict(X_val)
y_val_prob = model.predict_proba(X_val)[:, 1]
accuracy = accuracy_score(y_val, y_val_pred)
roc_auc = roc_auc_score(y_val, y_val_prob)

# Display the evaluation metrics
accuracy, roc_auc


import matplotlib.pyplot as plt
import numpy as np

# Plot the ROC AUC curve for visualization
from sklearn.metrics import roc_curve

fpr, tpr, _ = roc_curve(y_val, y_val_prob)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')
plt.title('ROC Curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.grid()
plt.show()

# Get feature importance for linear model (absolute value of coefficients)
feature_importance = np.abs(model.coef_[0])
features = X.columns

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(features, feature_importance)
plt.title('Feature Importance')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.grid()
plt.show()



# Fill missing values for 'Age' with the median
train_data['Age'].fillna(train_data['Age'].median(), inplace=True)
test_data['Age'].fillna(test_data['Age'].median(), inplace=True)

# Fill missing values for 'Embarked' with the mode
train_data['Embarked'].fillna(train_data['Embarked'].mode()[0], inplace=True)

# Convert 'Sex' and 'Embarked' columns to numeric using one-hot encoding
train_data = pd.get_dummies(train_data, columns=['Sex', 'Embarked'], drop_first=True)
test_data = pd.get_dummies(test_data, columns=['Sex', 'Embarked'], drop_first=True)

# Drop irrelevant columns (e.g., 'Name', 'Ticket', 'Cabin')
train_data.drop(['PassengerId'], axis=1, inplace=True)
test_data.drop(['PassengerId'], axis=1, inplace=True)

# Align the training and test datasets to have the same features
train_data, test_data = train_data.align(test_data, join='left', axis=1)
test_data.fillna(0, inplace=True)


X_train = train_data.drop('Survived', axis=1)
y_train = train_data['Survived']

# Split the training data for validation
X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# Train Logistic Regression Model
logreg = LogisticRegression(max_iter=1000, random_state=42)
logreg.fit(X_train_split, y_train_split)

# Validate the model
y_val_pred = logreg.predict(X_val)

# Evaluate the model
print("Validation Accuracy:", accuracy_score(y_val, y_val_pred))
print("Confusion Matrix:\n", confusion_matrix(y_val, y_val_pred))
print("Classification Report:\n", classification_report(y_val, y_val_pred))

# Test the model on the test dataset (if labels for 'Survived' are available in test set)
if 'Survived' in test_data.columns:
    X_test = test_data.drop('Survived', axis=1)
    y_test = test_data['Survived']
    y_test_pred = logreg.predict(X_test)

    print("Test Accuracy:", accuracy_score(y_test, y_test_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_test_pred))
    print("Classification Report:\n", classification_report(y_test, y_test_pred))
else:
    # Predict survival for the test dataset (no ground truth)
    predictions = logreg.predict(test_data)
    print("Predictions for test data:\n", predictions)
